{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this notebook contains the code written by the first beta tester (my mom!) :)\n",
    "\n",
    "# setting up some boilerplate code to get them started:\n",
    "# import libraries necessary for building the CNN\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, Dense, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "# libraries necessary for visualization\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important variables\n",
    "num_classes = 10 # one for each of the digits from 0-9\n",
    "batch_size = None # your choice! \n",
    "epochs = None # your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import mnist data from keras\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the x data do it's 4 dimensional --> the last dimension represents color channels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# we need to normalize the X data before feeding into our model\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# we also need to convert the Y data into one-hot vectors\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in the next section, we'll take a look at what your model is actually \"thinking\"\n",
    "\n",
    "# this is a function that will become helpful in the next cell:\n",
    "\n",
    "# creating a function to deprocess the image \n",
    "from scipy.misc import imsave\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to black/white representation\n",
    "    x *= 255\n",
    "    #x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the model's fileters\n",
    "\n",
    "from keras import backend as K #the backend in this case is tensorflow, since keras is sitting on top of it\n",
    "                                #so importing the \"backend\" will allow us to write code in tensorflow that keras\n",
    "                                #will be able to use for our model\n",
    "\n",
    "# create a dictionary of the model's layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "        \n",
    "#we'll be sending in an image the size of one of the MNIST images\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "        \n",
    "layer_name = \"conv2d_3\"\n",
    "filter_index = 0 #there are 32 filters, so this could be any number in the range 0-31\n",
    "\n",
    "# create a loss function that we will use to maximize the activation of the specified layer\n",
    "layer_output = layer_dict[layer_name].output # accesing the output of the specified layer stored in our dictionary\n",
    "loss = K.mean(layer_output[:,:,:, filter_index]) # averaging all the outputs of the filter --> remember that the filter\n",
    "                                                # is a 2-D \"square\" --> the middle two numbers represent height/width\n",
    "                                                # of that square, the first number represents batch size, and the \n",
    "                                                # final number represents the number of filters (we're accessing a\n",
    "                                                # specific one here)\n",
    "# compute the gradient of the input picture with respect to this loss.\n",
    "# this means we'll be updating the pixels of the input image, not the weights of the network --> clever!\n",
    "grads = K.gradients(loss, model.input)[0] # I don't know what the [0] means at the end of this line\n",
    "print(grads)\n",
    "\n",
    "# normalizing the gradient --> we don't want the magnitude of our gradient ascent/descent step to be infuenced heavily \n",
    "# by the gradient --> the gradient gives us the direction we want to take --> so normalizing helps the optimization\n",
    "# algorithm perform better\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "iterate = K.function([model.input], [loss, grads]) # this is a fancy way of writing a custom function that takes\n",
    "                                                # an input image as an input, and returns the loss and gradients\n",
    "                                                # for that image\n",
    "\n",
    "# running gradient ascent to maximize the activations of the filter\n",
    "# generating a grey test image\n",
    "input_img = np.random.random((1, img_width, img_height, 1)) * 20 + 128.\n",
    "\n",
    "# Choosing an arbitrary value for \"step\" --> pretty sure this is like the learning rate\n",
    "step = 5\n",
    "\n",
    "# 20 steps of gradient ascent\n",
    "for i in range(50):\n",
    "    loss_value, grads_value = iterate([input_img])\n",
    "    input_img += grads_value * step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's see the filter!\n",
    "# to see other filters, go and change the filter_index variable above\n",
    "\n",
    "img = input_img\n",
    "img = deprocess_image(img)\n",
    "\n",
    "# the imsave approach\n",
    "#imsave('%s_filter_%d.png' % (layer_name, filter_index), img)\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "# the matplotlib approach\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.squeeze())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
