{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries necessary for building the CNN\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, Dense, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important variables\n",
    "num_classes = 10 # one for each of the digits from 0-9\n",
    "batch_size = 128 #tunable number\n",
    "epochs = 13 #tunable number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import mnist data from keras\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the x data do it's 4 dimensional --> I think the last dimension represents color channels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# we need to normalize the X data before feeding into our model\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# we also need to convert the Y data into one-hot vectors\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# building the architecture of the convolutional model\n",
    "model = Sequential() #this will allow us to build a linear stack of layers --> hmmm is this restrictive in any way?\n",
    "                    # we may not want to limit folks to only a linear stack of layers, because this could\n",
    "                    # prevent them from making cool skip connections and stuff like that . . . something to consider\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = (28,28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/13\n",
      "60000/60000 [==============================] - 44s 728us/step - loss: 0.2799 - acc: 0.9211 - val_loss: 0.1188 - val_acc: 0.9679\n",
      "Epoch 2/13\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 0.0943 - acc: 0.9732 - val_loss: 0.0733 - val_acc: 0.9780\n",
      "Epoch 3/13\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0622 - acc: 0.9824 - val_loss: 0.0625 - val_acc: 0.9808\n",
      "Epoch 4/13\n",
      "60000/60000 [==============================] - 30s 495us/step - loss: 0.0490 - acc: 0.9856 - val_loss: 0.0596 - val_acc: 0.9800\n",
      "Epoch 5/13\n",
      "60000/60000 [==============================] - 29s 475us/step - loss: 0.0394 - acc: 0.9886 - val_loss: 0.0602 - val_acc: 0.9797\n",
      "Epoch 6/13\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 0.0333 - acc: 0.9903 - val_loss: 0.0571 - val_acc: 0.9820\n",
      "Epoch 7/13\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.0589 - val_acc: 0.9813\n",
      "Epoch 8/13\n",
      "60000/60000 [==============================] - 27s 449us/step - loss: 0.0234 - acc: 0.9934 - val_loss: 0.0598 - val_acc: 0.9827\n",
      "Epoch 9/13\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.0202 - acc: 0.9944 - val_loss: 0.0650 - val_acc: 0.9794\n",
      "Epoch 10/13\n",
      "60000/60000 [==============================] - 26s 434us/step - loss: 0.0169 - acc: 0.9954 - val_loss: 0.0627 - val_acc: 0.9815\n",
      "Epoch 11/13\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.0150 - acc: 0.9961 - val_loss: 0.0659 - val_acc: 0.9807\n",
      "Epoch 12/13\n",
      "60000/60000 [==============================] - 24s 408us/step - loss: 0.0124 - acc: 0.9968 - val_loss: 0.0668 - val_acc: 0.9813\n",
      "Epoch 13/13\n",
      "60000/60000 [==============================] - 24s 408us/step - loss: 0.0098 - acc: 0.9980 - val_loss: 0.0696 - val_acc: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c21da4eb8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the training data\n",
    "model.fit(X_train, Y_train, batch_size = batch_size, epochs=epochs, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
