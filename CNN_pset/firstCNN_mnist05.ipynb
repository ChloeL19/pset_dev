{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/chloeloughridge/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# the goal in this notebook is to visualize the filters of the simple CNN model\n",
    "\n",
    "# import libraries necessary for building the CNN\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, Dense, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for plotting the model\n",
    "# !pip install pydot\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important variables\n",
    "num_classes = 10 # one for each of the digits from 0-9\n",
    "batch_size = 128 #tunable number\n",
    "epochs = 13 #tunable number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import mnist data from keras\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the x data do it's 4 dimensional --> the last dimension represents color channels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# we need to normalize the X data before feeding into our model\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# we also need to convert the Y data into one-hot vectors\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# building the architecture of the convolutional model\n",
    "model = Sequential() #this will allow us to build a linear stack of layers --> hmmm is this restrictive in any way?\n",
    "                    # we may not want to limit folks to only a linear stack of layers, because this could\n",
    "                    # prevent them from making cool skip connections and stuff like that . . . something to consider\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = (28,28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the model on the training data\n",
    "model.fit(X_train, Y_train, batch_size = batch_size, epochs=epochs, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./CNN01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 184.58 264.00\" width=\"185pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 180.5762,-260 180.5762,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 47649516400 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>47649516400</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 176.5762,-255.5 176.5762,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2881\" y=\"-233.3\">conv2d_3_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 47649516344 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>47649516344</title>\n",
       "<polygon fill=\"none\" points=\"25.2622,-146.5 25.2622,-182.5 151.314,-182.5 151.314,-146.5 25.2622,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2881\" y=\"-160.3\">conv2d_3: Conv2D</text>\n",
       "</g>\n",
       "<!-- 47649516400&#45;&gt;47649516344 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>47649516400-&gt;47649516344</title>\n",
       "<path d=\"M88.2881,-219.4551C88.2881,-211.3828 88.2881,-201.6764 88.2881,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.7882,-192.5903 88.2881,-182.5904 84.7882,-192.5904 91.7882,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47649517184 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>47649517184</title>\n",
       "<polygon fill=\"none\" points=\"32.6553,-73.5 32.6553,-109.5 143.9209,-109.5 143.9209,-73.5 32.6553,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2881\" y=\"-87.3\">flatten_3: Flatten</text>\n",
       "</g>\n",
       "<!-- 47649516344&#45;&gt;47649517184 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>47649516344-&gt;47649517184</title>\n",
       "<path d=\"M88.2881,-146.4551C88.2881,-138.3828 88.2881,-128.6764 88.2881,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.7882,-119.5903 88.2881,-109.5904 84.7882,-119.5904 91.7882,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47649626376 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>47649626376</title>\n",
       "<polygon fill=\"none\" points=\"36.1621,-.5 36.1621,-36.5 140.4141,-36.5 140.4141,-.5 36.1621,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.2881\" y=\"-14.3\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 47649517184&#45;&gt;47649626376 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>47649517184-&gt;47649626376</title>\n",
       "<path d=\"M88.2881,-73.4551C88.2881,-65.3828 88.2881,-55.6764 88.2881,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.7882,-46.5903 88.2881,-36.5904 84.7882,-46.5904 91.7882,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pydot\n",
    "#plot_model(model, to_file='model01.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format=\"svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# going to visualize the filters of the model  . . . \n",
    "# inspiration from here: https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n",
    "\n",
    "# create a dictionary of the model's layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gradients_40/conv2d_3/convolution_grad/Conv2DBackpropInput:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K #the backend in this case is tensorflow, since keras is sitting on top of it\n",
    "                                #so importing the \"backend\" will allow us to write code in tensorflow that keras\n",
    "                                #will be able to use for our model\n",
    "        \n",
    "#we'll be sending in an image the size of one of the MNIST images\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "        \n",
    "layer_name = \"conv2d_3\"\n",
    "filter_index = 0 #there are 32 filters, so this could be any number in the range 0-31\n",
    "\n",
    "# create a loss function that we will use to maximize the activation of the specified layer\n",
    "layer_output = layer_dict[layer_name].output # accesing the output of the specified layer stored in our dictionary\n",
    "loss = K.mean(layer_output[:,:,:, filter_index]) # averaging all the outputs of the filter --> remember that the filter\n",
    "                                                # is a 2-D \"square\" --> the middle two numbers represent height/width\n",
    "                                                # of that square, the first number represents batch size, and the \n",
    "                                                # final number represents the number of filters (we're accessing a\n",
    "                                                # specific one here)\n",
    "# compute the gradient of the input picture with respect to this loss.\n",
    "# this means we'll be updating the pixels of the input image, not the weights of the network --> clever!\n",
    "grads = K.gradients(loss, model.input)[0] # I don't know what the [0] means at the end of this line\n",
    "print(grads)\n",
    "\n",
    "# normalizing the gradient --> we don't want the magnitude of our gradient ascent/descent step to be infuenced heavily \n",
    "# by the gradient --> the gradient gives us the direction we want to take --> so normalizing helps the optimization\n",
    "# algorithm perform better\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "iterate = K.function([model.input], [loss, grads]) # this is a fancy way of writing a custom function that takes\n",
    "                                                # an input image as an input, and returns the loss and gradients\n",
    "                                                # for that image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# running gradient ascent to maximize the activations of the filter\n",
    "\n",
    "# generating a grey test image\n",
    "input_img = np.random.random((1, img_width, img_height, 1)) * 20 + 128.\n",
    "\n",
    "# Choosing an arbitrary value for \"step\" --> pretty sure this is like the learning rate\n",
    "step = 5\n",
    "\n",
    "# 20 steps of gradient ascent\n",
    "for i in range(50):\n",
    "    loss_value, grads_value = iterate([input_img])\n",
    "    input_img += grads_value * step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a function to deprocess the image \n",
    "from scipy.misc import imsave\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to black/white representation\n",
    "    x *= 255\n",
    "    #x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# saving the image as a file\n",
    "img = input_img\n",
    "img = deprocess_image(img)\n",
    "\n",
    "# the imsave approach\n",
    "#imsave('%s_filter_%d.png' % (layer_name, filter_index), img)\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "# the matplotlib approach\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
